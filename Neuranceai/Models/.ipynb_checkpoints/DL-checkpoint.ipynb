{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21dfa0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from subprocess import check_output\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import csv\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.cross_validation import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "\n",
    "\n",
    "# DLL\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import add\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import utils\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (Attention, \n",
    "                                     Layer,\n",
    "                                     Add, concatenate, \n",
    "                                     Input, \n",
    "                                     Dense,  \n",
    "                                     LSTM, Bidirectional, GRU,\n",
    "                                     ZeroPadding2D, \n",
    "                                     Convolution2D, Conv2D, \n",
    "                                     GlobalAveragePooling2D, GlobalAvgPool2D, GlobalMaxPooling2D, GlobalMaxPool2D, \n",
    "                                     AveragePooling2D, AvgPool2D, MaxPooling2D, MaxPool2D,\n",
    "                                     Flatten,\n",
    "                                     BatchNormalization, \n",
    "                                     Dropout)\n",
    "\n",
    "from tensorflow.keras.layers import (Activation, \n",
    "                                     ReLU, \n",
    "                                     LeakyReLU, \n",
    "                                     Softmax)\n",
    "\n",
    "from tensorflow.keras.optimizers import (SGD,\n",
    "                                         Adam,\n",
    "                                         Adagrad,\n",
    "                                         Adadelta,\n",
    "                                         RMSprop,\n",
    "                                         Nadam)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509c3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be5ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt(name):\n",
    "    with open(name, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def load_pickle(name):\n",
    "    with open(name, \"rb\") as handle:\n",
    "        return pickle.load(handle)\n",
    "    \n",
    "def dump_pickle(name, file):\n",
    "    with open(name, \"wb\") as handle:\n",
    "        pickle.dump(file, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67925947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>review_0</th>\n",
       "      <th>review_1</th>\n",
       "      <th>review_2</th>\n",
       "      <th>review_3</th>\n",
       "      <th>review_4</th>\n",
       "      <th>review_5</th>\n",
       "      <th>review_6</th>\n",
       "      <th>review_7</th>\n",
       "      <th>review_8</th>\n",
       "      <th>...</th>\n",
       "      <th>review_763</th>\n",
       "      <th>review_764</th>\n",
       "      <th>review_765</th>\n",
       "      <th>review_766</th>\n",
       "      <th>review_767</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>len_review_by_patient_unique_word</th>\n",
       "      <th>base_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>0.059691</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>0.080178</td>\n",
       "      <td>-0.266999</td>\n",
       "      <td>-0.264136</td>\n",
       "      <td>-0.360968</td>\n",
       "      <td>0.64633</td>\n",
       "      <td>0.423532</td>\n",
       "      <td>-0.074173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065599</td>\n",
       "      <td>-0.351725</td>\n",
       "      <td>-0.171581</td>\n",
       "      <td>0.362696</td>\n",
       "      <td>-0.022024</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>8.022969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>-0.477708</td>\n",
       "      <td>-0.197286</td>\n",
       "      <td>-0.113292</td>\n",
       "      <td>-0.019980</td>\n",
       "      <td>-0.573079</td>\n",
       "      <td>-0.220722</td>\n",
       "      <td>0.34921</td>\n",
       "      <td>-0.051921</td>\n",
       "      <td>-0.013572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230648</td>\n",
       "      <td>-0.213165</td>\n",
       "      <td>-0.396574</td>\n",
       "      <td>0.421274</td>\n",
       "      <td>0.357504</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>56</td>\n",
       "      <td>7.858458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 774 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  review_0  review_1  review_2  review_3  review_4  review_5  \\\n",
       "0      206461  0.059691  0.008081  0.080178 -0.266999 -0.264136 -0.360968   \n",
       "1       95260 -0.477708 -0.197286 -0.113292 -0.019980 -0.573079 -0.220722   \n",
       "\n",
       "   review_6  review_7  review_8  ...  review_763  review_764  review_765  \\\n",
       "0   0.64633  0.423532 -0.074173  ...   -0.065599   -0.351725   -0.171581   \n",
       "1   0.34921 -0.051921 -0.013572  ...    0.230648   -0.213165   -0.396574   \n",
       "\n",
       "   review_766  review_767  effectiveness_rating  drug_approved_by_UIC  \\\n",
       "0    0.362696   -0.022024                     9             20-May-12   \n",
       "1    0.421274    0.357504                     8             27-Apr-10   \n",
       "\n",
       "   number_of_times_prescribed  len_review_by_patient_unique_word  base_score  \n",
       "0                          27                                 10    8.022969  \n",
       "1                         192                                 56    7.858458  \n",
       "\n",
       "[2 rows x 774 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_features_data = pd.read_csv(\"../ix_word/final_features.csv\", index_col=\"Unnamed: 0\")\n",
    "drug_features_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e645f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32165 entries, 0 to 32164\n",
      "Columns: 774 entries, patient_id to base_score\n",
      "dtypes: float64(769), int64(4), object(1)\n",
      "memory usage: 190.2+ MB\n"
     ]
    }
   ],
   "source": [
    "drug_features_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b127e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32165, 773), (32165,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_features_data_X = drug_features_data.drop(columns=[\"base_score\"])\n",
    "drug_features_data_y = drug_features_data[\"base_score\"]\n",
    "drug_features_data_X.shape, drug_features_data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec1077ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 772)\n",
      "(10000,)\n",
      "(22165, 772)\n",
      "(22165,)\n"
     ]
    }
   ],
   "source": [
    "train_data_X = drug_features_data_X.iloc[:10000, :].drop(columns=[\"drug_approved_by_UIC\"]).values\n",
    "print(train_data_X.shape)\n",
    "train_data_y = drug_features_data_y.iloc[:10000].values\n",
    "print(train_data_y.shape)\n",
    "validate_data_X = drug_features_data_X.iloc[10000:, :].drop(columns=[\"drug_approved_by_UIC\"]).values\n",
    "print(validate_data_X.shape)\n",
    "validate_data_y = drug_features_data_y.iloc[10000:].values\n",
    "print(validate_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db3fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X = scaler_X.fit_transform(train_data_X)\n",
    "y = scaler_y.fit_transform(train_data_y.reshape((10000, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "799e93ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'review_0', 'review_1', 'review_2', 'review_3',\n",
       "       'review_4', 'review_5', 'review_6', 'review_7', 'review_8',\n",
       "       ...\n",
       "       'review_762', 'review_763', 'review_764', 'review_765', 'review_766',\n",
       "       'review_767', 'effectiveness_rating', 'drug_approved_by_UIC',\n",
       "       'number_of_times_prescribed', 'len_review_by_patient_unique_word'],\n",
       "      dtype='object', length=773)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_features_data_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3c1af09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_0</th>\n",
       "      <th>review_1</th>\n",
       "      <th>review_2</th>\n",
       "      <th>review_3</th>\n",
       "      <th>review_4</th>\n",
       "      <th>review_5</th>\n",
       "      <th>review_6</th>\n",
       "      <th>review_7</th>\n",
       "      <th>review_8</th>\n",
       "      <th>review_9</th>\n",
       "      <th>...</th>\n",
       "      <th>review_758</th>\n",
       "      <th>review_759</th>\n",
       "      <th>review_760</th>\n",
       "      <th>review_761</th>\n",
       "      <th>review_762</th>\n",
       "      <th>review_763</th>\n",
       "      <th>review_764</th>\n",
       "      <th>review_765</th>\n",
       "      <th>review_766</th>\n",
       "      <th>review_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518189</td>\n",
       "      <td>-0.666211</td>\n",
       "      <td>-0.701984</td>\n",
       "      <td>-0.419138</td>\n",
       "      <td>-0.121582</td>\n",
       "      <td>-1.171266</td>\n",
       "      <td>1.820828</td>\n",
       "      <td>-0.100598</td>\n",
       "      <td>0.809497</td>\n",
       "      <td>1.359895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.689624</td>\n",
       "      <td>0.237767</td>\n",
       "      <td>0.757872</td>\n",
       "      <td>-1.373769</td>\n",
       "      <td>-0.753375</td>\n",
       "      <td>-0.585022</td>\n",
       "      <td>-1.324590</td>\n",
       "      <td>0.753534</td>\n",
       "      <td>0.404539</td>\n",
       "      <td>-1.020174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.404446</td>\n",
       "      <td>-2.875758</td>\n",
       "      <td>-2.275079</td>\n",
       "      <td>2.179960</td>\n",
       "      <td>-2.866139</td>\n",
       "      <td>0.063305</td>\n",
       "      <td>-1.107439</td>\n",
       "      <td>-2.975004</td>\n",
       "      <td>1.270923</td>\n",
       "      <td>1.395325</td>\n",
       "      <td>...</td>\n",
       "      <td>2.473461</td>\n",
       "      <td>-1.286364</td>\n",
       "      <td>-0.608341</td>\n",
       "      <td>3.102615</td>\n",
       "      <td>1.117594</td>\n",
       "      <td>2.224613</td>\n",
       "      <td>0.265459</td>\n",
       "      <td>-1.410805</td>\n",
       "      <td>1.023071</td>\n",
       "      <td>1.568145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_0  review_1  review_2  review_3  review_4  review_5  review_6  \\\n",
       "0  0.518189 -0.666211 -0.701984 -0.419138 -0.121582 -1.171266  1.820828   \n",
       "1 -3.404446 -2.875758 -2.275079  2.179960 -2.866139  0.063305 -1.107439   \n",
       "\n",
       "   review_7  review_8  review_9  ...  review_758  review_759  review_760  \\\n",
       "0 -0.100598  0.809497  1.359895  ...   -0.689624    0.237767    0.757872   \n",
       "1 -2.975004  1.270923  1.395325  ...    2.473461   -1.286364   -0.608341   \n",
       "\n",
       "   review_761  review_762  review_763  review_764  review_765  review_766  \\\n",
       "0   -1.373769   -0.753375   -0.585022   -1.324590    0.753534    0.404539   \n",
       "1    3.102615    1.117594    2.224613    0.265459   -1.410805    1.023071   \n",
       "\n",
       "   review_767  \n",
       "0   -1.020174  \n",
       "1    1.568145  \n",
       "\n",
       "[2 rows x 768 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = list(drug_features_data_X.columns)\n",
    "col.pop(col.index(\"drug_approved_by_UIC\"))\n",
    "X = pd.DataFrame(X, columns = col)\n",
    "lstm_X = X.loc[:, \"review_0\":\"review_767\"]\n",
    "lstm_X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fe7cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd82a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde39a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c136c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca821352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>name_of_drug</th>\n",
       "      <th>use_case_for_drug</th>\n",
       "      <th>review_by_patient</th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>drug_approved_by_UIC</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>base_score</th>\n",
       "      <th>review_len</th>\n",
       "      <th>review_n_words</th>\n",
       "      <th>review_by_patient_filter</th>\n",
       "      <th>review_by_patient_unique_word</th>\n",
       "      <th>len_review_by_patient_unique_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10091</th>\n",
       "      <td>223808</td>\n",
       "      <td>Depakote ER</td>\n",
       "      <td>Epilepsy</td>\n",
       "      <td>\"After trying 4 different meds this one was th...</td>\n",
       "      <td>8</td>\n",
       "      <td>1-Apr-08</td>\n",
       "      <td>15</td>\n",
       "      <td>7.633384</td>\n",
       "      <td>370</td>\n",
       "      <td>74</td>\n",
       "      <td>after trying 4 different meds this one was the...</td>\n",
       "      <td>['effect', 'trying', '4', 'possible', 'quit', ...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>35602</td>\n",
       "      <td>Anexsia</td>\n",
       "      <td>Pain</td>\n",
       "      <td>\"Worked better than Tylenol w/codeine #3 and C...</td>\n",
       "      <td>10</td>\n",
       "      <td>1-Apr-08</td>\n",
       "      <td>19</td>\n",
       "      <td>6.127475</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>worked better than tylenol w codeine  3 and ca...</td>\n",
       "      <td>['3', 'carisoprodol', 'better', 'codeine', 'ty...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id name_of_drug use_case_for_drug  \\\n",
       "10091      223808  Depakote ER          Epilepsy   \n",
       "1009        35602      Anexsia              Pain   \n",
       "\n",
       "                                       review_by_patient  \\\n",
       "10091  \"After trying 4 different meds this one was th...   \n",
       "1009   \"Worked better than Tylenol w/codeine #3 and C...   \n",
       "\n",
       "       effectiveness_rating drug_approved_by_UIC  number_of_times_prescribed  \\\n",
       "10091                     8             1-Apr-08                          15   \n",
       "1009                     10             1-Apr-08                          19   \n",
       "\n",
       "       base_score  review_len  review_n_words  \\\n",
       "10091    7.633384         370              74   \n",
       "1009     6.127475          88              14   \n",
       "\n",
       "                                review_by_patient_filter  \\\n",
       "10091  after trying 4 different meds this one was the...   \n",
       "1009   worked better than tylenol w codeine  3 and ca...   \n",
       "\n",
       "                           review_by_patient_unique_word  \\\n",
       "10091  ['effect', 'trying', '4', 'possible', 'quit', ...   \n",
       "1009   ['3', 'carisoprodol', 'better', 'codeine', 'ty...   \n",
       "\n",
       "       len_review_by_patient_unique_word  \n",
       "10091                                 35  \n",
       "1009                                  10  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_train_data = pd.read_csv(\"drug_preprocess.csv\", index_col=\"Unnamed: 0\")\n",
    "drug_train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15b621e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drug_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16876/4127269275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_train_name_use_review\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrug_train_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"combine_name_use_review\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'drug_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "all_train_name_use_review = list(drug_train_data[\"combine_name_use_review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a6720bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "size of vocabulary = 3167 in our trainig data\n"
     ]
    }
   ],
   "source": [
    "def ixtoword_wordtoix():\n",
    "    ixtoword = {}\n",
    "    wordtoix = {}\n",
    "    ix = 1\n",
    "    for w in vocab:\n",
    "        wordtoix[w] = ix\n",
    "        ixtoword[ix] = w\n",
    "        ix += 1\n",
    "    return ixtoword, wordtoix\n",
    "if 'wordtoix.pkl' in os.listdir(\"../ix_word\"):\n",
    "    print(\"load\")\n",
    "    ixtoword = load_pickle('../ix_word/ixtoword.pkl')\n",
    "    wordtoix = load_pickle('../ix_word/wordtoix.pkl')\n",
    "else:\n",
    "    ixtoword, wordtoix = ixtoword_wordtoix()\n",
    "    dump_pickle('../ix_word/ixtoword.pkl', ixtoword)\n",
    "    dump_pickle('../ix_word/wordtoix.pkl', wordtoix)\n",
    "    print(\"dump\")\n",
    "vocab_size = len(ixtoword) + 1\n",
    "print('size of vocabulary = %d in our trainig data' % (vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5865579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fad447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613c197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b366cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a41a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81af16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130891f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36a45873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effectiveness_rating</th>\n",
       "      <th>number_of_times_prescribed</th>\n",
       "      <th>len_review_by_patient_unique_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.612706</td>\n",
       "      <td>-0.035176</td>\n",
       "      <td>-1.505655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.308694</td>\n",
       "      <td>4.487901</td>\n",
       "      <td>0.913186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   effectiveness_rating  number_of_times_prescribed  \\\n",
       "0              0.612706                   -0.035176   \n",
       "1              0.308694                    4.487901   \n",
       "\n",
       "   len_review_by_patient_unique_word  \n",
       "0                          -1.505655  \n",
       "1                           0.913186  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_X= X.loc[:, \"effectiveness_rating\":\"len_review_by_patient_unique_word\"]\n",
    "mlp_X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4da84791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dim =768\n",
    "# vocab_size = 2986\n",
    "# max_length = 83\n",
    "# input_shape = 2048\n",
    "# # CNN\n",
    "# inputs1 = Input(shape=(input_shape,))\n",
    "\n",
    "# fe1 = Dropout(0.2)(inputs1)\n",
    "# fe1 = Dense(256)(fe1)\n",
    "# fe1 = BatchNormalization()(fe1)\n",
    "# fe1 = ReLU()(fe1)\n",
    "\n",
    "\n",
    "# # RNN - input --> bert embedding --> LSTM --> LSTM\n",
    "# inputs2 = Input(shape=(max_length,))\n",
    "# se1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "# se1 = Dropout(0.2)(se1)\n",
    "# se1 = BatchNormalization()(se1)\n",
    "# se1 = Bidirectional(LSTM(128))(se1)\n",
    "\n",
    "\n",
    "# # Add both LSTM and CNN\n",
    "# decoder1 = concatenate([fe1, se1])\n",
    "# decoder1 = Dropout(0.2)(decoder1)\n",
    "# decoder1 = Dense(2048)(decoder1)\n",
    "# decoder1 = BatchNormalization()(decoder1)\n",
    "# decoder1 = ReLU()(decoder1)\n",
    "# decoder1 = Dropout(0.2)(decoder1)\n",
    "# outputs = Dense(vocab_size, activation=\"softmax\")(decoder1)\n",
    "\n",
    "\n",
    "# m1 = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "# m1.summary(), m1.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45b61154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 3)            0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 32)           128         ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 32)          128         ['dense_15[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 32)           0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 1, 768)]     0           []                               \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 32)           0           ['re_lu_12[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 1, 768)       0           ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 1, 768)       0           ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          4224        ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 1, 768)      3072        ['dropout_22[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 1, 768)      3072        ['dropout_23[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 128)         512         ['dense_16[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " bidirectional_7 (Bidirectional  (None, 256)         918528      ['batch_normalization_22[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_8 (Bidirectional  (None, 128)         426496      ['batch_normalization_23[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 128)          0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 512)          0           ['bidirectional_7[0][0]',        \n",
      "                                                                  'bidirectional_8[0][0]',        \n",
      "                                                                  're_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 512)          0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 512)         2048        ['dropout_26[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 128)          65664       ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 128)          0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 128)          0           ['re_lu_14[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 128)         512         ['dropout_27[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 32)           4128        ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 32)           0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 32)           0           ['re_lu_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 32)          128         ['dropout_28[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            33          ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,428,673\n",
      "Trainable params: 1,423,937\n",
      "Non-trainable params: 4,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " [<keras.engine.input_layer.InputLayer at 0x22d0fcd91f0>,\n",
       "  <keras.layers.core.dropout.Dropout at 0x22d61a803a0>,\n",
       "  <keras.layers.core.dense.Dense at 0x22d61a6a190>,\n",
       "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x22d61a59a90>,\n",
       "  <keras.layers.advanced_activations.ReLU at 0x22d0eec9a60>,\n",
       "  <keras.engine.input_layer.InputLayer at 0x22d61ababe0>,\n",
       "  <keras.layers.core.dropout.Dropout at 0x22d10092370>,\n",
       "  <keras.layers.core.dropout.Dropout at 0x22d61abaee0>,\n",
       "  <keras.layers.core.dropout.Dropout at 0x22d0f29bf70>,\n",
       "  <keras.layers.core.dense.Dense at 0x22d10083af0>,\n",
       "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x22d0fe04dc0>,\n",
       "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x22d75870250>,\n",
       "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x22d5f6f8b50>,\n",
       "  <keras.layers.wrappers.Bidirectional at 0x22d758727f0>,\n",
       "  <keras.layers.wrappers.Bidirectional at 0x22d61a80a30>,\n",
       "  <keras.layers.advanced_activations.ReLU at 0x22d0ff84c40>,\n",
       "  <keras.layers.merge.Concatenate at 0x22d0ff843a0>,\n",
       "  <keras.layers.core.dropout.Dropout at 0x22d37711370>,\n",
       "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x22d0f79e2e0>,\n",
       "  <keras.layers.core.dense.Dense at 0x22d0fb19100>,\n",
       "  <keras.layers.advanced_activations.ReLU at 0x22d0ff844c0>,\n",
       "  <keras.layers.core.dropout.Dropout at 0x22d0fd71cd0>,\n",
       "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x22d0f7526d0>,\n",
       "  <keras.layers.core.dense.Dense at 0x22d0fd712e0>,\n",
       "  <keras.layers.advanced_activations.ReLU at 0x22d0f752220>,\n",
       "  <keras.layers.core.dropout.Dropout at 0x22d0fdd53d0>,\n",
       "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x22d0fdd54f0>,\n",
       "  <keras.layers.core.dense.Dense at 0x22d0fdceca0>])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim =768\n",
    "vocab_size = 2986\n",
    "max_length = 83\n",
    "lstm_input_shape = 768\n",
    "mlp_input_shape = 3\n",
    "\n",
    "# RNN - input --> bert embedding --> LSTM --> LSTM\n",
    "inputs1 = Input(shape=(1, lstm_input_shape,)) # 768\n",
    "# em1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs1)\n",
    "se1 = Dropout(0.2)(inputs1)\n",
    "se1 = BatchNormalization()(se1)\n",
    "se1 = Bidirectional(LSTM(128))(se1)\n",
    "se2 = Dropout(0.2)(inputs1)\n",
    "se2 = BatchNormalization()(se2)\n",
    "se2 = Bidirectional(LSTM(64))(se2)\n",
    "\n",
    "inputs2 = Input(shape=(mlp_input_shape,)) # 3\n",
    "\n",
    "fe1 = Dropout(0.2)(inputs2)\n",
    "fe1 = Dense(32)(fe1)\n",
    "fe1 = BatchNormalization()(fe1)\n",
    "fe1 = ReLU()(fe1)\n",
    "fe1 = Dropout(0.2)(fe1)\n",
    "fe1 = Dense(128)(fe1)\n",
    "fe1 = BatchNormalization()(fe1)\n",
    "fe1 = ReLU()(fe1)\n",
    "\n",
    "\n",
    "# Add both LSTM and CNN\n",
    "decoder1 = concatenate([se1, se2, fe1])\n",
    "decoder1 = Dropout(0.2)(decoder1)\n",
    "decoder1 = BatchNormalization()(decoder1)\n",
    "decoder1 = Dense(128)(decoder1)\n",
    "decoder1 = ReLU()(decoder1)\n",
    "decoder1 = Dropout(0.2)(decoder1)\n",
    "decoder1 = BatchNormalization()(decoder1)\n",
    "decoder1 = Dense(32)(decoder1)\n",
    "decoder1 = ReLU()(decoder1)\n",
    "decoder1 = Dropout(0.2)(decoder1)\n",
    "decoder1 = BatchNormalization()(decoder1)\n",
    "outputs = Dense(1, kernel_initializer='normal', activation='linear')(decoder1)\n",
    "\n",
    "m1 = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "m1.summary(), m1.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f9df64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #                                                  34,         30\n",
    "# def data_generator(description, photos, wordtoix, max_length, num_photos_per_batch):\n",
    "#     X1, X2, y = list(), list(), list()\n",
    "# #     X1, X2, X3, y = list(), list(), list(), list()\n",
    "#     n=0\n",
    "#     # loop for ever over images\n",
    "#     while 1:\n",
    "#         for key, desc_list in description.items():\n",
    "#             n+=1\n",
    "#             # retrieve the photo feature\n",
    "#             photo = photos[key]\n",
    "# #             photo2 = simple_model_feature[key+'.jpg']\n",
    "# #             photo2 = encode2(f'data/images/{key}.jpg')\n",
    "# #             photo2 = img_to_array(load_img(f'data/images/{key}.jpg', target_size=(299, 299)))\n",
    "\n",
    "#             for desc in desc_list:\n",
    "#                 # print(desc)\n",
    "#                 # encode the sequence\n",
    "# #                 seq = \n",
    "#                 seq = [wordtoix[word] for word in desc.split(' ') if word in wordtoix]\n",
    "#                 # split one sequence into multiple X, y pairs\n",
    "#                 for i in range(1, len(seq)):\n",
    "#                     # split into input and output pair\n",
    "#                     in_seq, out_seq = seq[:i], seq[i]\n",
    "#                     # pad input sequence\n",
    "#                     in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "#                     # encode output sequence\n",
    "#                     out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "#                     # store\n",
    "#                     X1.append(photo) # All photos\n",
    "#                     X2.append(in_seq) # \n",
    "# #                     X3.append(in_seq)\n",
    "#                     y.append(out_seq)\n",
    "\n",
    "#             if n==num_photos_per_batch:\n",
    "# #                 print(n)\n",
    "#                 yield ([array(X1), array(X2)], array(y))\n",
    "# #                 print(\"hello\")\n",
    "#                 X1, X2, y = list(), list(), list()\n",
    "#                 n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94374e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                    768,    3,   1\n",
    "def data_generator(lstm_X, mlp_X, out, num_record_per_batch):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n=0\n",
    "    while 1:\n",
    "        for i in range(lstm_X.shape[0]):\n",
    "            n+=1\n",
    "            # retrieve the photo feature\n",
    "            a = lstm_X[i]\n",
    "            X1.append(a)\n",
    "            b = mlp_X[i]\n",
    "            X2.append(b)\n",
    "            y.append(out[i])\n",
    "\n",
    "            if n==num_record_per_batch:\n",
    "                print(n)\n",
    "                print(array(X1).shape)\n",
    "                print(array(X2).shape)\n",
    "                print(\"ggg\", len(y))\n",
    "                yield ([array(X1), array(X2)], array(y))\n",
    "                print(\"hello\")\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b742036",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "#     tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(name = \"precision\"),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "#     tf.keras.metrics.mean_absolute_error(\"mean_absolute_error\"),\n",
    "#     tf.keras.metrics.mean_squared_error(name=\"mean_squared_error\"),\n",
    "    tfa.metrics.RSquare(name=\"r_square\")\n",
    "]\n",
    "# m1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "m1.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.0001), metrics=[\"accuracy\", METRICS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5ae0050",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a6ee554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/embedding_1/embedding_lookup' defined at (most recent call last):\n    File \"E:\\python\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\python\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\python\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"E:\\python\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"E:\\python\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_16876/2662387758.py\", line 1, in <module>\n      m1.fit([lstm_X.values, mlp_X.values], y, epochs=500, batch_size=32, validation_split = 0.2)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 197, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_1/embedding_1/embedding_lookup'\nindices[30,2] = -1 is not in [0, 2986)\n\t [[{{node model_1/embedding_1/embedding_lookup}}]] [Op:__inference_train_function_62685]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16876/2662387758.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlstm_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlp_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/embedding_1/embedding_lookup' defined at (most recent call last):\n    File \"E:\\python\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\python\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\python\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"E:\\python\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"E:\\python\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_16876/2662387758.py\", line 1, in <module>\n      m1.fit([lstm_X.values, mlp_X.values], y, epochs=500, batch_size=32, validation_split = 0.2)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\python\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 197, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_1/embedding_1/embedding_lookup'\nindices[30,2] = -1 is not in [0, 2986)\n\t [[{{node model_1/embedding_1/embedding_lookup}}]] [Op:__inference_train_function_62685]"
     ]
    }
   ],
   "source": [
    "m1.fit([lstm_X.values, mlp_X.values], y, epochs=500, batch_size=32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7117d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1.fit([lstm_X.values, mlp_X.values], y, epochs=100, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7beb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.experimental_run_functions_eagerly(True)\n",
    "epochs = 200\n",
    "batch_size = 2\n",
    "steps = X.shape[0]//batch_size\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "    print(f\"epoch no {i}\")\n",
    "    generator = data_generator(lstm_X.values, mlp_X.values, y, batch_size)\n",
    "    m1.fit(generator, epochs=1, batch_size=batch_size, steps_per_epoch=steps, verbose=1) \n",
    "    m1.save(f\"model/arm_{i}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0076211a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5edb7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tf.config.experimental_run_functions_eagerly(True)\n",
    "# epochs = 200\n",
    "# batch_size = 2\n",
    "# steps = len(train_img_capt)//batch_size\n",
    "\n",
    "# for i in range(1, epochs+1):\n",
    "#     print(f\"epoch no {i}\")\n",
    "#     generator = data_generator(train_img_capt, train_features, wordtoix, max_length, batch_size)\n",
    "#     m1.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1) \n",
    "#     m1.save(f\"model/tipa_{i}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee513a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
